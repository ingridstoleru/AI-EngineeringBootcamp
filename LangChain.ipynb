{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c363947-3558-4413-b25a-69e8073fc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa47a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8690b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ff43d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce04cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "completion = client.chat.completions.create(model = \"gpt-4\",\n",
    "                                            messages = [{\"role\": \"system\", \"content\": \"You are Marv, a chatbot that reluctanly answers questions with sarcastic responses.\"},\n",
    "                                                       {\"role\": \"user\", \"content\": \"I recently adopted a dog. Could you suggest some dog names?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b0ea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, absolutely! How about \"Sir Barksalot\" or \"Madame Woofington\"? Maybe \"Captain PuddleMaker\"? Or if you\\'re really feeling daring, why not \"Mr. Chew Your Favorite Shoes\"? There\\'s also the timeless classic, \"Lady StinkBomb\". All foolproof choices, truly.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c15c8f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_sentiment_analysis = openai.OpenAI()\n",
    "completion = client_sentiment_analysis.chat.completions.create(model = \"gpt-4\",\n",
    "                                              messages = [{\"role\": \"system\", \"content\": \"You are a sentiment analysis model. You will be given a text and you need to analyze the sentiment of the text.\"},\n",
    "                                                         {\"role\": \"user\", \"content\": \"I am very happy with the service I received from the company.\"},\n",
    "                                                         {\"role\": \"assistant\", \"content\": \"Positive\"},\n",
    "                                                         {\"role\": \"user\", \"content\": \"I am very sad with the service I received from the company.\"},\n",
    "                                                         {\"role\": \"assistant\", \"content\": \"Negative\"},\n",
    "                                                         {\"role\": \"user\", \"content\": \"I am neutral with the service I received from the company.\"},\n",
    "                                                         {\"role\": \"assistant\", \"content\": \"Neutral\"},\n",
    "                                                         {\"role\": \"user\", \"content\": \"This is so unfair.\"}])\n",
    "completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060837cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_max_token_poc = openai.OpenAI()\n",
    "completion = client_max_token_poc.chat.completions.create(model = \"gpt-4\",\n",
    "                                                          messages = [{\"role\": \"system\", \"content\": \"You are Marv, a chatbot that reluctanly answers questions with sarcastic responses.\"},\n",
    "                                                         {\"role\": \"user\", \"content\": \"Could you explain briefly what a block hole is?\"}],\n",
    "                                                          max_tokens = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75b40fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, absolutely! It's just a delightful little place in space where gravity is so strong that nothing, not even light, can escape it. Think of it as the universe's version of that one friend who never returns stuff they borrow. Charmingly powerful, and seemingly very, very hungry. It's made when massive stars collapse under their own gravity during a supernova explosion. So, basically, the stellar version of having a mid-life crisis.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f2e93e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. This intense gravity is due to a large amount of matter being compressed into a very small space. Black holes are usually formed when a large star collapses under its own gravity after a supernova explosion. They are invisible and can only be detected through their effects on nearby objects or light.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educational_poc = openai.OpenAI()\n",
    "completion = educational_poc.chat.completions.create(model = \"gpt-4\",\n",
    "                                                    messages = [{\"role\": \"user\", \"content\": \"Could you explain briefly what a block hole is?\"}],\n",
    "                                                    temperature = 0,\n",
    "                                                    seed = 365)\n",
    "\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8d462db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\istoleru\\AppData\\Local\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name = \"gpt-4\", model_kwargs = {\"seed\": 365}, temperature = 0, max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7aec338",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(\"I've recently adopted a dog. Could you suggest some dog names?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d5acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some suggestions:\n",
      "\n",
      "Male Dog Names:\n",
      "1. Max\n",
      "2. Charlie\n",
      "3. Cooper\n",
      "4. Buddy\n",
      "5. Jack\n",
      "6. Rocky\n",
      "7. Duke\n",
      "8. Bear\n",
      "9. Zeus\n",
      "10. Toby\n",
      "\n",
      "Female Dog Names:\n",
      "1. Bella\n",
      "2. Lucy\n",
      "3. Daisy\n",
      "4. Luna\n",
      "5. Lola\n",
      "6. Sadie\n",
      "7. Molly\n",
      "8. Bailey\n",
      "9. Stella\n",
      "10. Maggie\n",
      "\n",
      "Unisex Dog Names\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d0d9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e87312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_human = HumanMessage(content = \"I've recently adopted a dog. Could you suggest some dog names?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "913f3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b43e183f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here are some suggestions:\n",
      "\n",
      "Male Dog Names:\n",
      "1. Max\n",
      "2. Charlie\n",
      "3. Cooper\n",
      "4. Buddy\n",
      "5. Jack\n",
      "6. Rocky\n",
      "7. Duke\n",
      "8. Bear\n",
      "9. Zeus\n",
      "10. Toby\n",
      "\n",
      "Female Dog Names:\n",
      "1. Bella\n",
      "2. Lucy\n",
      "3. Daisy\n",
      "4. Luna\n",
      "5. Lola\n",
      "6. Sadie\n",
      "7. Molly\n",
      "8. Bailey\n",
      "9. Stella\n",
      "10. Zoe\n",
      "\n",
      "Unisex Dog Names\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fecad1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_system = SystemMessage(content = \"You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af3b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke([message_system, message_human])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0508e014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new furball. How about \"Bark Twain\" if it's a literary hound, or \"Sir Wag-a-lot\" if it's got a tail that won't quit? Maybe \"Bark Zuckerberg\" if it's tech-savvy, or \"Biscuit\" if it's... well, a bit of a biscuit. You're welcome.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c786035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because nothing screams \"I need help\" like not being able to name your own cat. How about \"Furry McFurFace\", \"Sir Meows A Lot\", or \"Clawsome\"? Or if you're into irony, you could go with \"Dog\". You're welcome.\n"
     ]
    }
   ],
   "source": [
    "message_human_cat = HumanMessage(content = \"I've recently adopted a cat. Could you suggest some cat names?\")\n",
    "response = chat.invoke([message_system, message_human_cat])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "711541b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\istoleru\\AppData\\Local\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat_with_assistant = ChatOpenAI(model_name = \"gpt-4\", model_kwargs = {\"seed\": 365}, temperature = 0, max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b200ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! How about \"Finley\" or \"Bubbles\"? If you're into puns, you could go with \"Gillbert\" or \"Finnegan\". For a more regal touch, \"King Neptune\" or \"Queen Atlantica\" could work. If you're a movie fan, \"Nemo\" or \"Dory\" might be a good fit. Enjoy your new aquatic friend!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "message_human_dog = HumanMessage(content = \"I've recently adopted a dog. Could you suggest some dog names?\")\n",
    "message_ai_dog = AIMessage(content = '''Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new furball. How about \"Bark Twain\" if it's a literary hound, or \"Sir Wag-a-lot\" if it's got a tail that won't quit? Maybe \"Bark Zuckerberg\" if it's tech-savvy, or \"Biscuit\" if it's... well, a bit of a biscuit. You're welcome.''')\n",
    "\n",
    "message_human_cat = HumanMessage(content = \"I've recently adopted a cat. Could you suggest some cat names?\")\n",
    "message_ai_cat = AIMessage(content = ''' Oh, absolutely. Because nothing screams \"I need help\" like not being able to name your own cat. How about \"Furry McFurFace\", \"Sir Meows A Lot\", or \"Clawsome\"? Or if you're into irony, you could go with \"Dog\". You're welcome. ''')\n",
    "\n",
    "message_human_fish = HumanMessage(content = \"I've recently adopted a fish. Could you suggest some fish names?\")\n",
    "# teach it how to give sarcastic responses through the few shot prompting technique\n",
    "response_with_assistant = chat_with_assistant.invoke([message_human_dog, message_ai_dog, message_human_cat, message_ai_cat, message_human_fish])\n",
    "\n",
    "print(response_with_assistant.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3aeae32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2c07f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = ''' \n",
    "System:\n",
    "{description}\n",
    "\n",
    "Human:\n",
    "I've recently adopted a {pet}. Could you suggest some {pet} names?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7862f6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, template=\" \\nSystem:\\n{description}\\n\\nHuman:\\nI've recently adopted a {pet}. Could you suggest some {pet} names?\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(TEMPLATE)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b127bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = prompt_template.invoke({\"description\": \"The chatbot should reluctantly answers questions with sarcastic responses.\", \"pet\": \"dog\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34819edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content=\" \\nSystem:\\nThe chatbot should reluctantly answers questions with sarcastic responses.\\n\\nHuman:\\nI've recently adopted a dog. Could you suggest some dog names?\\n\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43c2014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\istoleru\\AppData\\Local\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat_prompt_template = ChatOpenAI(model_name = \"gpt-4\", model_kwargs = {\"seed\": 365}, temperature = 0, max_tokens = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33e83fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = ''' I've recently adopted a {pet}. Could you suggest some {pet} names?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b9e66317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "\n",
    "message_template_s = SystemMessagePromptTemplate.from_template(TEMPLATE_S)\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1cfd8168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d0c40220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\" I've recently adopted a {pet}. Could you suggest some {pet} names?\"), additional_kwargs={})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02b76e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f876c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\" I've recently adopted a {pet}. Could you suggest some {pet} names?\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc8d930b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='The chatbot should reluctantly answers questions with sarcastic responses.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" I've recently adopted a dog. Could you suggest some dog names?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value = chat_template.invoke({\"description\": \"The chatbot should reluctantly answers questions with sarcastic responses.\", \"pet\": \"dog\"})\n",
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b955c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_prompt_template.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b8ba4408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Oh, absolutely. Because I\\'m the ultimate authority on dog names, right? How about \"Bark Twain\" or \"Sir Wag-a-lot\"? Maybe \"Droolius Caesar\" or \"Bark Obama\"? Or if you\\'re into pop culture, \"Bark Vader\" or \"Wooferine\"? I mean, who wouldn\\'t want their dog to have a name that\\'s a terrible pun?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 85, 'prompt_tokens': 37, 'total_tokens': 122, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-COJg9D2YeV2tk3iYLgVhaf92YT6pS', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5b7d0828-8bfc-4ec9-bcab-ad11f88a8187-0', usage_metadata={'input_tokens': 37, 'output_tokens': 85, 'total_tokens': 122, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "596d6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3ed9141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\istoleru\\AppData\\Local\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat_few_shot = ChatOpenAI (model_name = \"gpt-4\", model_kwargs = {\"seed\": 365}, temperature = 0, max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71d41707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import AIMessagePromptTemplate\n",
    "\n",
    "TEMPLATE_H = ''' I've recently adopted a {pet}. Could you suggest some {pet} names?'''\n",
    "TEMPLATE_AI = '''{response}'''\n",
    "\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(TEMPLATE_H)\n",
    "message_template_ai = AIMessagePromptTemplate.from_template(TEMPLATE_AI)\n",
    "\n",
    "example_template = ChatPromptTemplate.from_messages([message_template_h, message_template_ai])\n",
    "\n",
    "examples = [{'pet': 'dog', \n",
    "             'response': '''Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new furball. \n",
    "                        How about \"Bark Twain\" if it's a literary hound, or \"Sir Wag-a-lot\" if it's got a tail that won't quit? Maybe \"Bark Zuckerberg\" if it's tech-savvy, or \"Biscuit\" if it's... well, a bit of a biscuit. You're welcome.'''},\n",
    "            {'pet': 'cat', \n",
    "             'response': ''' Oh, absolutely. Because nothing screams \"I need help\" like not being able to name your own cat. \n",
    "                        How about \"Furry McFurFace\", \"Sir Meows A Lot\", or \"Clawsome\"? Or if you're into irony, you could go with \"Dog\". You're welcome. '''}]\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = example_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd000871",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([example_prompt, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bedace2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({\"pet\": \"rabbit\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a22e3e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\" I've recently adopted a dog. Could you suggest some dog names?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Oh, absolutely. Because nothing screams \"I\\'m a responsible pet owner\" like asking a chatbot to name your new furball. \\n                        How about \"Bark Twain\" if it\\'s a literary hound, or \"Sir Wag-a-lot\" if it\\'s got a tail that won\\'t quit? Maybe \"Bark Zuckerberg\" if it\\'s tech-savvy, or \"Biscuit\" if it\\'s... well, a bit of a biscuit. You\\'re welcome.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" I've recently adopted a cat. Could you suggest some cat names?\", additional_kwargs={}, response_metadata={}), AIMessage(content=' Oh, absolutely. Because nothing screams \"I need help\" like not being able to name your own cat. \\n                        How about \"Furry McFurFace\", \"Sir Meows A Lot\", or \"Clawsome\"? Or if you\\'re into irony, you could go with \"Dog\". You\\'re welcome. ', additional_kwargs={}, response_metadata={}), HumanMessage(content=\" I've recently adopted a rabbit. Could you suggest some rabbit names?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc0807b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human:  I've recently adopted a dog. Could you suggest some dog names?\n",
      "\n",
      "ai: Oh, absolutely. Because nothing screams \"I'm a responsible pet owner\" like asking a chatbot to name your new furball. \n",
      "                        How about \"Bark Twain\" if it's a literary hound, or \"Sir Wag-a-lot\" if it's got a tail that won't quit? Maybe \"Bark Zuckerberg\" if it's tech-savvy, or \"Biscuit\" if it's... well, a bit of a biscuit. You're welcome.\n",
      "\n",
      "human:  I've recently adopted a cat. Could you suggest some cat names?\n",
      "\n",
      "ai:  Oh, absolutely. Because nothing screams \"I need help\" like not being able to name your own cat. \n",
      "                        How about \"Furry McFurFace\", \"Sir Meows A Lot\", or \"Clawsome\"? Or if you're into irony, you could go with \"Dog\". You're welcome. \n",
      "\n",
      "human:  I've recently adopted a rabbit. Could you suggest some rabbit names?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in chat_value.messages:\n",
    "    print(f\"{i.type}: {i.content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8097bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_few_shot.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c447856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! How about \"Thumper\", \"Bun Bun\", \"Cotton\", \"Nibbles\", \"Fluffy\", \"Snowball\", \"Carrot\", \"Hopper\", \"Cinnabun\", or \"Peanut\"?\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "46f80882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\istoleru\\AppData\\Local\\anaconda3\\envs\\langchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3519: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_output_parser = ChatOpenAI(model_name = \"gpt-4\", model_kwargs = {\"seed\": 365}, temperature = 0, max_tokens = 100)\n",
    "\n",
    "message_h = HumanMessage(content = \"Can you give me an interesting fact that I probably didn't know about?\")\n",
    "\n",
    "response = chat.invoke([message_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e44ddc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Did you know that octopuses have three hearts? Two pump blood to the gills, while the third pumps it to the rest of the body.\n"
     ]
    }
   ],
   "source": [
    "str_output_parser = StrOutputParser()\n",
    "response_parsed = str_output_parser.invoke(response)\n",
    "\n",
    "print(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7a3d29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've recently adopted a dog. Could you suggest some dog names?  \n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "\n",
    "message_h = HumanMessage(content = f'''I've recently adopted a dog. Could you suggest some dog names?  \n",
    "{CommaSeparatedListOutputParser().get_format_instructions()}''')\n",
    "\n",
    "print(message_h.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "258f972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max, Bella, Charlie, Lucy, Cooper, Daisy, Buddy, Lola, Rocky, Sadie, Zeus, Molly, Jack, Bailey, Toby, Stella, Duke, Roxy, Oliver, Luna\n"
     ]
    }
   ],
   "source": [
    "response = chat.invoke([message_h])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "10442185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.datetime import DatetimeOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c1e1babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When was the Danish poet Piet Hein born?\n",
      "                        Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 2023-07-04T14:30:00.000000Z, 1999-12-31T23:59:59.999999Z, 2025-01-01T00:00:00.000000Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "message_h = HumanMessage(content = f'''When was the Danish poet Piet Hein born?\n",
    "                        {DatetimeOutputParser().get_format_instructions()}''')\n",
    "\n",
    "print(message_h.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0268e8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1905-12-16T00:00:00.000000Z\n"
     ]
    }
   ],
   "source": [
    "response = chat.invoke([message_h])\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
